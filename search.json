[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Notas em Econometria",
    "section": "",
    "text": "Disclaimer\nEste projeto teve início com base nas notas de aula do Prof. Dr. Fernando Aiube e do Prof. Dr. Francis Petterini, assim como nas notas de aula do Kotze (2019) e nos livros: Box et al. (2015), Hamilton (1994) e Enders (2014). O trabalho ainda precisa ser concluído e revisado. Vale destacar que pretendo incluir formas de aplicar os modelos em .\nA idealização do projeto surgiu como uma maneira de estudo para eu aprender tanto a teoria quanto a aplicação prática de cada modelo. A implementação dos modelos será feita do zero, utilizando o mínimo de pacotes possível.\nAlguns scripts estarão disponíveis dentro do texto, mas todos poderão ser acessados no meu GitHub.\nLembrando que a ideia é sempre utilizar o minimo de pacotes possiveis:\n\n# Importações globais\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\n\n\nBox, George EP, Gwilym M Jenkins, Gregory C Reinsel, e Greta M Ljung. 2015. Time series analysis: forecasting and control. John Wiley & Sons.\n\n\nEnders, W. 2014. Applied Econometric Times Series. Wiley Series em Probability e Statistics. Wiley. https://books.google.com.br/books?id=lmr9oQEACAAJ.\n\n\nHamilton, James Douglas. 1994. Time series analysis. Princeton university press.\n\n\nKotze, Kevin. 2019. «Time Series Analusis». 2019. https://www.economodel.com/time-series-analysis-2019.",
    "crumbs": [
      "Disclaimer"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introdução",
    "section": "",
    "text": "1.1 Regressão linear\nRegressão linear é uma ferramenta estatística usada para modelar a relação entre uma variável dependente e uma ou mais variáveis independentes, assumindo que essa relação pode ser descrita por uma linha reta. A ideia de se utilizar é uma é dado a sua simplicidade, tendo apenas um parâmetro de inclinação e um de intercepto, uma outra é que aqui se assume que as variáveis apresentam uma relação linear. A linha representa a melhor aproximação da tendência central dos dados. Aqui devemos partir de uma amostra, um par ordenado \\(\\{x_{i},y_{i}\\}^{N}_{i=1}\\), encontrar uma reta que melhor se ajusta a média dos dados, para isso, vamos partir da equação de uma reta. \\[\ny=\\alpha + \\beta x\n\\]\nOnde a ideia aqui é querer entender qual relação em que a variável \\(x\\) afeta a variável \\(y\\), temos então que resolver dois problemas: primeiro é encontrar os parâmetros \\(\\alpha\\) e \\(\\beta\\) que melhor se ajusta, sabendo que nem todo o \\(y\\) pode ser explicado pelo \\(x\\), temos que adicionar uma variável à equação que consiga captar essa relação no modelo, essa variável será dada por \\(u\\).\nPodemos reescrever a equação acima como sendo um sistema de equações lineares \\[\n\\begin{aligned}\n  y_{1} &= \\alpha + \\beta x_{1} + u_{1} \\\\\n  y_{2} &= \\alpha + \\beta x_{2} + u_{2} \\\\\n  y_{3} &= \\alpha + \\beta x_{3} + u_{3} \\\\\n  & \\vdots \\\\\n  y_{n} &= \\alpha + \\beta x_{n} + u_{n}\n\\end{aligned}\n\\]\nNote que esse é um sistema de \\(n\\) equações lineares com \\(n + 2\\) incógnitas. E que pela regra de Cramer, sabemos que o sistema apresenta infinitas soluções. O que não nos ajuda e precisamos voltar ao problema, quais valores de \\(\\alpha\\) e \\(\\beta\\) que melhor se ajusta? Uma maneira de se fazer isso, é minimizar a soma do erro quadrático \\(\\left(\\sum_{i=1}^{N} u_i^{2}\\right)\\) e para isso, vamos isolar o erro, elevar tudo ao quadrado e aplicar a recursividade. \\[\n\\sum_{i=1}^{N} u_i^{2} = \\sum_{i=1}^{N} (y_{i} - \\alpha - \\beta x_{i})^{2}\n\\]\nDado isso, podemos dizer que podemos estimar valores de \\(\\alpha\\) e \\(\\beta\\) que minimizam o erro quadrático. Seja \\(S(\\alpha, \\beta) = \\sum_{i=1}^{N} u_i^{2}\\) e sabendo que os valores dos parâmetros que zeram o gradiente \\(\\nabla = \\left(\\frac{\\partial S}{\\partial \\hat{\\alpha}}, \\frac{\\partial S}{\\partial \\hat{\\beta}}\\right)=0\\) são os valores que minimizam o erro quadrático. Fazendo as derivadas… \\[\n\\begin{aligned}\n  \\nabla = \\begin{bmatrix}\n    \\dfrac{\\partial S}{\\partial \\hat{\\alpha}} \\\\\n    \\dfrac{\\partial S}{\\partial \\hat{\\beta}}\n  \\end{bmatrix} = \\begin{bmatrix}\n    -2\\sum_{i=1}^{N} (y_{i} - \\hat{\\alpha} - \\hat{\\beta} x_{i}) \\\\\n    -2\\sum_{i=1}^{N} (y_{i} - \\hat{\\alpha} - \\hat{\\beta} x_{i})(x_{i})\n  \\end{bmatrix} = 0\n\\end{aligned}\n\\]\nPodemos multiplicar ambos os lados por \\(-\\frac{1}{2}\\) e abrir o somatório1. \\[\n\\begin{aligned}\n  \\begin{bmatrix}\n    \\sum_{i=1}^{N} y_{i} - n\\hat{\\alpha} - \\hat{\\beta}\\sum_{i=1}^{N} x_{i} \\\\\n    \\sum_{i=1}^{N} y_{i}x_{i} - \\hat{\\alpha}\\sum_{i=1}^{N}x_{i} - \\hat{\\beta}\\sum_{i=1}^{N} x_{i}^{2}\n  \\end{bmatrix} = 0\n\\end{aligned}\n\\]\nSeparando os termos, temos que \\[\n\\begin{aligned}\n  \\begin{bmatrix}\n    \\sum_{i=1}^{N} y_{i} \\\\\n    \\sum_{i=1}^{N} y_{i}x_{i}\n  \\end{bmatrix} =\n  \\begin{bmatrix}\n    n\\hat{\\alpha} + \\hat{\\beta}\\sum_{i=1}^{N} x_{i} \\\\\n    \\hat{\\alpha}\\sum_{i=1}^{N}x_{i} + \\hat{\\beta}\\sum_{i=1}^{N} x_{i}^{2}\n  \\end{bmatrix}\n\\end{aligned}\n\\] \\[\n\\begin{aligned}\n  \\begin{bmatrix}\n    \\sum_{i=1}^{N} y_{i} \\\\\n    \\sum_{i=1}^{N} y_{i}x_{i}\n  \\end{bmatrix} =\n  \\begin{bmatrix}\n    n & \\sum_{i=1}^{N} x_{i} \\\\\n    \\sum_{i=1}^{N} x_{i} & \\sum_{i=1}^{N} x_{i}^{2}\n  \\end{bmatrix}\n  \\begin{bmatrix}\n    \\hat{\\alpha} \\\\\n    \\hat{\\beta}\n  \\end{bmatrix}\n\\end{aligned}\n\\]\nPodemos reorganizar da seguinte maneira: \\[\n\\begin{bmatrix}\nn & \\sum_{i=1}^{N} x_{i} \\\\\n\\sum_{i=1}^{N} x_{i} & \\sum_{i=1}^{N} x_{i}^{2}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{\\alpha} \\\\\n\\hat{\\beta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sum_{i=1}^{N} y_{i} \\\\\n\\sum_{i=1}^{N} y_{i}x_{i}\n\\end{bmatrix}\n\\]\nPré-multiplicando ambos os lados pelo inverso da matriz que tem os valores de \\(x\\): \\[\n\\begin{bmatrix}\n\\hat{\\alpha} \\\\\n\\hat{\\beta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nn & \\sum_{i=1}^{N} x_{i} \\\\\n\\sum_{i=1}^{N} x_{i} & \\sum_{i=1}^{N} x_{i}^{2}\n\\end{bmatrix}^{-1}\n\\begin{bmatrix}\n\\sum_{i=1}^{N} y_{i} \\\\\n\\sum_{i=1}^{N} y_{i}x_{i}\n\\end{bmatrix}\n\\]\nPara termos certeza de que este é o ponto mínimo, devemos avaliar a matriz hessiana: \\[\nH =\n\\begin{bmatrix}\n\\dfrac{\\partial^2 S}{\\partial \\alpha^2} & \\dfrac{\\partial^2 S}{\\partial \\alpha \\, \\partial \\beta} \\\\\n\\dfrac{\\partial^2 S}{\\partial \\alpha \\, \\partial \\beta} & \\dfrac{\\partial^2 S}{\\partial \\beta^2}\n\\end{bmatrix}\n\\]\nLogo: \\[\nH =\n\\begin{bmatrix}\nn & \\sum x_{i} \\\\\n\\sum x_{i} & \\sum x_{i}^{2}\n\\end{bmatrix}\n\\]\nPara ser um mínimo global, devemos ter que:\nCom isso, podemos dizer que é um ponto de mínimo.\nPodemos reescrever: \\[\n\\begin{bmatrix}\nn & \\sum x_{i} \\\\\n\\sum x_{i} & \\sum x_{i}^{2}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{\\alpha} \\\\\n\\hat{\\beta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\sum y_{i} \\\\\n\\sum x_{i} y_{i}\n\\end{bmatrix}\n\\]\nAbrindo: \\[\n\\begin{bmatrix}\n1 & 1 & \\dots & 1 \\\\\nx_{1} & x_{2} & \\dots & x_{n}\n\\end{bmatrix}'\n\\begin{bmatrix}\n1 & x_{1} \\\\\n1 & x_{2} \\\\\n\\vdots \\\\\n1 & x_{n}\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{\\alpha} \\\\\n\\hat{\\beta}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{n}\n\\end{bmatrix}\n\\]\nOnde: \\[\nX =\n\\begin{bmatrix}\n1 & 1 & \\dots & 1 \\\\\nx_{1} & x_{2} & \\dots & x_{n}\n\\end{bmatrix}'\n\\] \\[\n\\hat{B} =\n\\begin{bmatrix}\n\\hat{\\alpha} \\\\\n\\hat{\\beta}\n\\end{bmatrix}\n\\] \\[\nY =\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\n\\vdots \\\\\ny_{n}\n\\end{bmatrix}\n\\]\nEntão: \\[\nX' \\hat{B} = X' Y\n\\] \\[\n(X' X) \\hat{B} = X' Y\n\\] \\[\n(X' X)^{-1} (X' X) \\hat{B} = (X' X)^{-1} X' Y\n\\] \\[\n\\hat{B} = (X' X)^{-1} X' Y\n\\] \\[\n\\boxed{\\hat{B} = (X' X)^{-1} X' Y}\n\\]\nEntão, sempre que estamos falando do estimador do MQO, estamos nos referindo à Equação 1.1: \\[\n\\hat{B} = (X' X)^{-1} X' Y\n\\tag{1.1}\\]\nAgora, temos que pensar da seguinte maneira: dado que conseguimos construir os estimadores, como podemos criar seus intervalos de confiança? Para isso, podemos substituir \\(Y\\) por \\(XB + U\\):2 \\[\n\\hat{B} = (X' X)^{-1} X' (XB + U)\n\\] \\[\n= (X' X)^{-1} X' XB + (X' X)^{-1} X' U\n\\]\nAssumindo que os dados não tenham problema de multicolinearidade perfeita, a matriz \\((X' X)^{-1}\\) deve existir para que \\(I = (X' X)^{-1} X' X\\): \\[\n\\hat{B} = B + (X' X)^{-1} X' U\n\\tag{1.2}\\]\nObservamos na equação Equação 1.2 que a componente do estimador influenciada pelo erro, especificamente \\(X' U\\), ilustra uma premissa importante do modelo: \\(\\mathbb{E}(X | U) = 0\\). Isso implica que, idealmente, todas as variáveis explicativas deveriam ser exógenas, não apresentando qualquer correlação com o termo de erro. Mas, é importante reconhecer que, na prática, alcançar uma exogeneidade completa é praticamente inviável; assim, é realista esperar que qualquer modelo econômico possa manifestar algum nível, mesmo que mínimo, de endogeneidade.\nSubtraind os dois lados da Equação 1.2 por \\(-B\\) e pós-multiplicando por \\((\\hat{B} - B)'\\): \\[\n(\\hat{B} - B)(\\hat{B} - B)' = (X' X)^{-1} X' U[(X' X)^{-1} X' U]'\n\\]\nDesenvolvendo a parte esquerda dessa igualdade, temos que: \\[\n\\begin{bmatrix}\n\\hat{B}_{1} - B \\\\\n\\hat{B}_{2} - B\n\\end{bmatrix}\n\\begin{bmatrix}\n\\hat{B}_{1} - B & \\hat{B}_{2} - B\n\\end{bmatrix}'\n\\]\nMultiplicando e aplicando o operador da esperança: \\[\n\\begin{bmatrix}\n\\mathbb{E}[(\\hat{B}_{1} - B)^{2}] & \\mathbb{E}[(\\hat{B}_{1} - B)(\\hat{B}_{2} - B)] \\\\\n\\mathbb{E}[(\\hat{B}_{1} - B)(\\hat{B}_{2} - B)] & \\mathbb{E}[(\\hat{B}_{2} - B)^{2}]\n\\end{bmatrix}\n\\]\nOnde a diagonal principal é a variância de \\(\\hat{B}_{1}\\) e o resto é a covariância, então montamos a matriz de variância-covariância: \\[\n\\begin{bmatrix}\n\\text{Var}(\\hat{B}_{1}) & \\text{Cov}(\\hat{B}_{1}, \\hat{B}_{2}) \\\\\n\\text{Cov}(\\hat{B}_{1}, \\hat{B}_{2}) & \\text{Var}(\\hat{B}_{2})\n\\end{bmatrix}\n\\]\nA partir disso, poderíamos montar um intervalo de confiança para os betas se não fosse um pequeno problema… Aqui precisamos do valor de \\(\\beta\\), e que só Deus sabe. Vamos então olhar para o lado direito da igualdade3 \\[\n=(X' X)^{-1} X' UU' X[(X' X)^{-1}]'\n\\] \\[\n=(X' X)^{-1} X' UU' X(X' X)^{-1}\n\\]\nAbrindo \\(UU'\\) e aplicando o operador da esperança: \\[\nUU' =\n\\begin{bmatrix}\nu_1 \\\\\nu_2 \\\\\n\\vdots \\\\\nu_n\n\\end{bmatrix}\n\\begin{bmatrix}\nu_1 & u_2 & \\cdots & u_n\n\\end{bmatrix}'\n\\] \\[\n=\n\\begin{bmatrix}\n\\mathbb{E}(u_1)^{2} & \\mathbb{E}(u_1, u_2) & \\cdots & \\mathbb{E}(u_1, u_n) \\\\\n\\mathbb{E}(u_2, u_1) & \\mathbb{E}(u_2)^{2} & \\cdots & \\mathbb{E}(u_2, u_n) \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\mathbb{E}(u_n, u_1) & \\mathbb{E}(u_n, u_2) & \\cdots & \\mathbb{E}(u_n)^{2}\n\\end{bmatrix}\n\\] Vamos ter que na diagonal principal é a variância dos erros e \\(\\forall \\, \\mathbb{E}(u_{i}, u_{j})\\) em que \\(i \\neq j\\) temos a covariância dos erros. Sob as hipóteses de homoscedasticidade4 e não autocorrelação, vamos ter que:\n\\[\nUU' = \\begin{bmatrix}\n\\sigma^{2} & 0 & \\cdots & 0 \\\\\n0 & \\sigma^{2} & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\sigma^{2}\n\\end{bmatrix}\n\\]\n\\[\n= \\sigma^{2} \\begin{bmatrix}\n1 & 0 & \\cdots & 0 \\\\\n0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 1\n\\end{bmatrix}\n\\]\n\\[\n= \\sigma^{2} I\n\\]\nEntão continuando, vamos ter que:\n\\[\n(X' X)^{-1} X' \\sigma^{2} X(X' X)^{-1}\n\\]\n\\[\n= \\sigma^{2} (X' X)^{-1} X' X(X' X)^{-1}\n\\]\n\\[\n= \\sigma^{2} (X' X)^{-1}\n\\tag{1.3}\\]\nAgora sim temos uma matriz de variância-covariância(Equação 1.3), mas percebemos que ao longo do caminho foi necessário fazer algumas hipóteses questionáveis, como a homoscedasticidade e não-autocorrelação. Outro problema dessa matriz de variância-covariância é que nela precisamos da média do erro, mas só Deus sabe o erro… o máximo que podemos fazer é procurar uma estimativa para esse erro, e vamos chamá-lo de resíduo. Para diferenciar, o resíduo é a parte do modelo que não conseguimos explicar e o erro é tudo aquilo que afeta o \\(Y\\), mas não é o \\(X\\). Então um estimador para a variancia dos resíduos é: \\[\n\\hat{\\sigma}^2 = \\frac{SQR}{n-k} = \\frac{\\sum_{i=1}^{n} u^2}{n-k}\n\\] Onde:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#regressão-linear",
    "href": "intro.html#regressão-linear",
    "title": "1  Introdução",
    "section": "",
    "text": "O primeiro menor principal será \\(&gt; 0\\)\nO determinante do segundo menor principal será \\(&gt;0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(n \\rightarrow\\) Tamanho da amostra\n\\(k \\rightarrow\\) Numero de coeficientes\n\n\nEstimando uma regressao no python\nPrimeiro, vamos começar lendo os dados. Aqui vamos utilizar o dataset mtcars, juntos dos pacotes que serão usados\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n\nmtcars =  sm.datasets.get_rdataset('mtcars').data\n\nVamos agora criar uma função que estime os valores dos \\(\\hat{\\beta}\\) e calcula o erro padrão de cada coeficiente, isso é importante pois será usado mais tarde para o calculo das estatisticas \\(t\\). A Função recebe como um argumento ‘data’ nossa base de dados; y é a variavel dependete e x são nossas variáveis explicativas, note que da maneira que foi construida nossa função y e x deve ser strings.\n\ndef ols(data, y, x):\n    X = data[x].values\n    Y = data[y].values\n\n    # Adiciona uma coluna de \"1\" para gerar o intercepto\n    X = np.column_stack((np.ones(X.shape[0]), X))\n\n    # Calcula OLS\n    XtX = np.transpose(X) @ X\n    XtX_inv = np.linalg.inv(XtX)\n    XtY = np.transpose(X) @ Y\n\n    betas = XtX_inv @ XtY\n\n    # Calcula os resíduos\n    residuals = Y - X @ betas\n    sqr = np.sum(residuals**2)  # Soma dos quadrados dos resíduos\n    n, k = X.shape\n    residual_variance = sqr / (n - k)  # Variância dos resíduos\n\n    # Calcula o erro padrão dos coeficientes\n    standard_errors = np.sqrt(residual_variance * np.diag(XtX_inv))\n\n    return betas, standard_errors\n\ntendo nossos valores em mãos, precisamos de uma função que calcule as estatisticas t\n\ndef t_stats(betas, standard_errors):\n    # Calcula os valores-t\n    t_values = betas / standard_errors\n    return t_values\n\nPara organizar tudo e melhorar a visibilidade dos dados, precisamos de uma função que pegue todos esses valores que crie um dataframe\n\ndef results_dataframe(data, y, x):\n    # Calcula betas e erros padrão\n    betas, standard_errors = ols(data, y, x)\n    \n    # Calcula estatísticas t\n    t_values = t_stats(betas, standard_errors)\n    \n    # Cria um DataFrame para uma melhor visualização\n    coef_names = ['Intercept'] + x\n    results = pd.DataFrame({\n        'Coeficiente': betas,\n        'Erro Padrão': standard_errors,\n        'Estatistica t': t_values\n    }, index=coef_names)\n    \n    return results\n\nTemos entao\n\nresults_dataframe(mtcars, 'mpg', ['cyl', 'disp'])\n\n\n\n\n\n\n\n\nCoeficiente\nErro Padrão\nEstatistica t\n\n\n\n\nIntercept\n34.660995\n2.547004\n13.608536\n\n\ncyl\n-1.587277\n0.711844\n-2.229809\n\n\ndisp\n-0.020584\n0.010257\n-2.006696",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#conceitos-de-convergência",
    "href": "intro.html#conceitos-de-convergência",
    "title": "1  Introdução",
    "section": "1.2 Conceitos de Convergência",
    "text": "1.2 Conceitos de Convergência\nA ideia aqui é entender o que acontece com a amostra à medida que seu tamanho vai para infinito. Embora isso seja puramente teórico, conseguimos tirar algumas ideias para o caso da amostra finita. As duas ideias principais são:\n\nA lei dos grandes números diz que a média da amostra \\(X_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\) converge em probabilidade para a expectativa \\(\\mu = \\mathbb{E}(X_i)\\). Isso significa que \\(X_n\\) está próximo de \\(\\mu\\) com alta probabilidade.\nO teorema do limite central diz que \\(\\sqrt{n}(X_n - \\mu)\\) converge em distribuição para uma distribuição Normal. Isso significa que a média da amostra tem aproximadamente uma distribuição Normal para grandes valores de \\(n\\).\n\n\nDefinição 1.1 (Convergencia) A sequência5 de variáveis aleatórias, \\(X_{1}, X_{2}, \\ldots\\), converge em probabilidade para uma variável aleatória \\(X\\), se \\(\\forall \\varepsilon &gt; 0\\),\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(\\left|X_{n} - X\\right| \\geq \\varepsilon) = 0 \\quad \\text{ou} \\quad \\lim_{n \\to \\infty} \\mathbb{P}(\\left|X_{n} - X\\right| &lt; \\varepsilon) = 1\n\\]\nNote que se \\(n \\to \\infty \\implies \\left|X_{n} - X\\right| \\to 0\\) e isso quer dizer que no limite, a sequência vai se aproximar muito da variável aleatória.\n\n\nTeorema 1.1 (Teorema da Lei dos Grandes Números - Fraca) Seja \\(X_{1}, X_{2}, \\ldots\\), variáveis aleatórias iid com \\(\\mathbb{E}[X_{i}] = \\mu\\) e \\(\\text{Var}[X_{i}] = \\sigma^{2} &lt; \\infty\\). Defina \\(\\bar{X}_{n} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}\\). Então para todo \\(\\varepsilon &gt; 0\\):\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(|\\bar{X}_{n} - \\mu| &lt; \\varepsilon) = 1\n\\]\nEntão, \\(\\bar{X}_{n}\\) converge em probabilidade para \\(\\mu\\).\n\n\n\nMostrar código\ndef lei_grandes_numeros(pop_mean, pop_std, sample_sizes):\n    np.random.seed(0)  # Para reprodutibilidade\n\n    sample_means = [np.random.normal(pop_mean, pop_std, size).mean() for size in sample_sizes]\n\n    return np.array(sample_means)\n\npop_mean = 10\npop_std = 2\nn_simulations = 300\nsample_sizes = range(1, n_simulations + 1)\n\n# Gerando os dados\nsample_means = lei_grandes_numeros(pop_mean, pop_std,sample_sizes)\n\n# Visualização dos resultados\nplt.plot(sample_sizes, sample_means, label='Média amostral')\nplt.axhline(y=pop_mean, color='r', linestyle='-', label='Média populacional')\nplt.xlabel('Tamanho da Amostra')\nplt.ylabel('Média')\nplt.title('Demonstração da Lei dos Grandes Números')\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTeorema 1.2 (Teorema do Limite Central) Sejam \\(X_{1}, \\ldots, X_{n}\\) variáveis aleatórias independentes e identicamente distribuídas com média \\(\\mu\\) e variância \\(\\sigma^2\\). Seja \\(X_n = \\frac{1}{n} \\sum_{i=1}^n X_i\\). Então,\n\\[\nZ_n = \\frac{X_n - \\mu}{\\sqrt{\\frac{\\sigma^2}{n}}} = \\frac{\\sqrt{n}(X_n - \\mu)}{\\sigma}\n\\xrightarrow[n \\to \\infty]{} Z\n\\]\nonde \\(Z\\) tem uma distribuição normal padrão. Em outras palavras,\n\\[\n\\lim_{n \\to \\infty} \\mathbb{P}(Z_n \\leq z) = \\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2 \\pi}} e^{-x^2/2} \\, dx.\n\\]\n\n\n\nMostrar código\ndef tcl(N, pop):\n    size_sample = 100\n    sample_mean = [\n        np.random.choice(pop, size=size_sample, replace=True).mean() for _ in range(N)\n    ]\n    return np.array(sample_mean)\n\ndef plot_tcl(N_values, pop):\n\n    fig, axs = plt.subplots(1, len(N_values), figsize=(15, 5), sharey=True)\n    \n    for i, N in enumerate(N_values):\n        sample_means = tcl(N, pop)\n        axs[i].hist(sample_means, bins=30, edgecolor='k', alpha=0.7)\n        axs[i].set_title(f'{N} Amostras', fontsize=21)\n        axs[i].set_xlabel('Média da Amostra', fontsize=18)\n        axs[i].set_ylabel('Frequência', fontsize=18)\n\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n    plt.show()\n\nnp.random.seed(0)\n# Gerar a população\npop = np.random.uniform(size=1000)\n\n# Plota um histograma com diferentes números de amostras\nplot_tcl([50, 200, 1000], pop)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#séries-de-tempo",
    "href": "intro.html#séries-de-tempo",
    "title": "1  Introdução",
    "section": "1.3 Séries de tempo",
    "text": "1.3 Séries de tempo\nUma série de tempo é caracterizada por uma sequência de observações tomada sequencialmente no tempo. Podemos chamar essa sequência de observações $ (y_{1},y_{2},y_{3}…) $ como sendo variáveis aleatórias, onde \\(y = f(t) + \\varepsilon_{t}\\), em outras palavras, cada observação é uma função do tempo mais um fator aleatório (ruído branco). Como esse \\(y\\) depende do tempo, vamos ter um valor diferente de \\(y\\) para cada valor de \\(t=0,1,2,...,T\\); \\(y^{*} = f(t^{*}) + \\varepsilon_{t^{*}}\\). Então \\(y_{1}\\) é o valor de \\(y\\) no período 1, \\(y_{2}\\) é o valor de \\(y\\) no período 2 e assim vai. Uma série de tempo pode ser dividida entre um processo determinístico ou estocástico.\n\n1.3.1 Processo determinístico\nÉ um processo que não depende de um termo aleatório e sempre irá ter o mesmo resultado dado um valor inicial. O processo \\(T_{t} = 1 + 0,1t\\) é um processo determinístico, pois não depende de nenhum fator aleatório, estando sempre acompanhado de uma constante (1) e um termo de tendência determinística \\((0,1t)\\).\nPodemos observar essa função melhor, gerando o seguinte gráfico no Python.\n\n\nMostrar código\ndef trend(f):\n    x = np.linspace(0, 100, 1000) \n    y = f(x)  \n    \n    plt.clf()\n    plt.plot(x, y)\n    plt.title(r'$f(x) = 1 + 0.1x$')\n    plt.show()\n\n# f(x) = 1 + 0.1*x\ntrend(lambda x: 1 + 0.1 * x)\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Processo estocástico\nO que diferencia um processo estocástico do determinístico é o fator aleatório, por mais que esse fator seja aleatório ele apresenta uma função de distribuição de probabilidade, por mais que se saiba qual é o valor inicial de uma série, não dá para saber com exatidão o próximo valor, mas podemos atribuir probabilidades a diferentes valores.\n\n1.3.2.1 Ruído Branco\nUm ruído branco é uma sequência serial de variáveis aleatórias não correlacionadas com média zero e variância finita e constante, seria aquele erro \\((u)\\) da primeira parte do curso. Assumimos duas condições importantes para o ruído branco: ele deve ser independente um do outro e deve apresentar uma distribuição normal6. Sendo escrito da seguinte forma:\n\\[\n\\begin{aligned}\n\\varepsilon_{t} &\\sim i.i.d.\\mathcal{N}(0, \\sigma^2) \\\\\n\\varepsilon_{t} &\\sim RB(0, \\sigma^2)\n\\end{aligned}\n\\]\nO ruído branco assume 3 propriedades:\n\n\\(\\mathbb{E}[\\varepsilon_{t}] = \\mathbb{E}[\\varepsilon_{t} \\mid \\varepsilon_{t-1}, \\varepsilon_{t-2}, \\dotsc] = 0\\)\n\\(\\mathbb{E}[\\varepsilon_{t} \\varepsilon_{t-j}] = \\text{cov}[\\varepsilon_{t} \\varepsilon_{t-j}] = 0\\)\n\\(\\text{var}[\\varepsilon_{t}] = \\text{cov}[\\varepsilon_{t} \\varepsilon_{t}] = \\sigma^{2}_{\\varepsilon_{t}}\\)\n\nAs duas primeiras propriedades dizem respeito à impossibilidade de preditividade e à ausência de autocorrelação. A terceira diz respeito à homocedasticidade, a variância ser constante.\nPara visualizar isso, criei uma função em Python que gera um conjunto de dados de ruído branco usando a função np.random.normal() que cria um conjunto aleatório de dados de uma distribuição normal, onde \\(n\\) é o tamanho da amostra desejado.\n\n\nMostrar código\ndef white_noise(n):\n    np.random.seed(0)\n    white_noise = np.random.normal(0, 1, n)\n    \n    plt.clf()\n    plt.plot(white_noise)\n    plt.axhline(0, color = 'black')\n    plt.show()\n    \nwhite_noise(100)\n\n\n\n\n\n\n\n\n\n\n\n1.3.2.2 Passeio aleatório\nEsse tempo passeio aleatório se diz pelo fato de que o valor de uma variável em um determinado período é igual ao seu valor no período passado mais um fator aleatório determinado por \\(\\varepsilon_{t}\\), sendo descrito por:\n\\[\ny_{t} = y_{t-1} + \\varepsilon_{t}\n\\]\nVamos supor um valor inicial para \\(y_{t}\\) como sendo \\(y_{1}\\), então:\n\\[\n\\begin{aligned}\ny_{1} &= y_{0} + \\varepsilon_{1} \\\\\ny_{2} &= y_{1} + \\varepsilon_{2} \\\\\ny_{2} &= y_{0} + \\varepsilon_{1} + \\varepsilon_{2}\n\\end{aligned}\n\\]\nResolvendo isso recursivamente, temos:\n\\[\ny_{t} = y_{0} + \\sum_{i=1}^{t} \\varepsilon_{i}\n\\]\nSe \\(y_{0} \\sim 0\\), podemos então dizer que o passeio aleatório é uma soma acumulada de ruídos brancos:\n\\[\ny_{t} = \\sum_{i=1}^{t} \\varepsilon_{i}\n\\]\nPode acontecer o caso do passeio aleatório ter uma constante \\(\\gamma\\) adicionada:\n\\[\ny_{1} = \\gamma + y_{0} + \\varepsilon_{1}\n\\]\nLogo, quando \\(y_{0} \\sim 0\\), vamos ter que:\n\\[\ny_{t} = \\gamma t + \\sum_{i=1}^{t} \\varepsilon_{i}\n\\]\n\n\nMostrar código\ndef random_walk(trend, n):\n    np.random.seed(0)\n    \n    yt = np.zeros(n)\n    epsilon = np.random.normal(0,1,n)\n    for t in np.arange(1,n):\n        yt[t] = t * trend + np.sum(epsilon[:t+1])\n    \n    return yt\n\n\ndef plot_rw(trend_list, t):\n    plt.clf()\n    for trend in trend_list:\n        rw = random_walk(trend, t)\n        plt.plot(rw, label=f'Tendencia = {trend}')\n    \n    plt.legend()\n    plt.show()\n\ntrend_list = [0, 0.2, -0.2]\nplot_rw(trend_list, t=100)\n\n\n\n\n\n\n\n\n\n\n\n\n1.3.3 Estacionariedade e Autocorrelação\nAntes de entrar no assunto de autocorrelação, devemos ter em mente algumas propriedades referentes ao primeiro momento (esperança) e segundo momento (variância) de um passeio aleatório. O primeiro momento de um passeio aleatório pode ser calculado pela sua média:\n\\[\n\\mathbb{E}[y_{t}] = \\mathbb{E}[y_{0} + \\sum_{i=1}^{t} \\varepsilon_{i}] = \\mathbb{E}[y_{0}] + \\mathbb{E}[\\sum_{i=1}^{t} \\varepsilon_{i}] = \\mathbb{E}[y_{0}] + 0 = y_{0} = \\mu\n\\]\nNota-se que a esperança (média) de \\(y_{t}\\) não depende de \\(t\\), sendo uma constante e é por isso que estou chamando de \\(\\mu\\).\nO segundo momento é a variância:\n\\[\n\\text{Var}[y_{t}] = \\mathbb{E}[y_{t}^{2}] = \\mathbb{E}[(y_{t} - \\mathbb{E}[y_{t}])^{2}]\n\\] \\[\n= \\mathbb{E}[y_{t}^{2}] - \\mathbb{E}[y_{0}]^{2}\n\\] \\[\n= \\mathbb{E}[(y_{0} + \\sum \\varepsilon_{i})^{2}]\n\\] \\[\n= \\mathbb{E}[y_{0}^{2} + 2y_{0}\\sum \\varepsilon_{i} + \\sum \\varepsilon_{i}^{2}] - \\mu^{2}\n\\] \\[\n= \\mathbb{E}[y_{0}^{2}] + 2y_{0}\\sum \\mathbb{E}[\\varepsilon_{i}] + \\sum \\mathbb{E}[\\varepsilon_{i}^{2}] - \\mu^{2}\n\\] \\[\n= \\mu^{2} + 0 + \\sum \\sigma^{2} - \\mu^{2} = t \\sigma^{2}\n\\]\nPodemos observar que a variância de um processo aleatório não é constante, pois vai depender de \\(t\\).\nOutra parada importante é definir a covariância para \\(k\\) lags:\n\\[\n\\text{Cov}[y_{t},y_{t-k}] = \\mathbb{E} \\{ (y_{t} - \\mathbb{E}[y_{t}])(y_{t-k} - \\mathbb{E}[y_{t-k}]) \\} = \\mathbb{E} [(y_{t} - \\mu)(y_{t-k} - \\mu )]\n\\]\n\n\n1.3.4 Estacionariedade\nA hipótese da estacionariedade é um caso particular do processo estocástico, no qual se assume que o processo está em um estado de equilíbrio. O caso dos processos estritamente estacionários (estacionariedade forte) é quando todas as suas propriedades (momentos) não são afetadas pelo tempo. Como essas condições são muito restritas, na grande maioria das vezes nos referimos a esse processo estocástico como fracamente estacionário, ou covariância-estacionário, ou estacionário de segunda ordem. Isso quer dizer que apenas a média e a variância devem ser constantes e que a covariância deve depender apenas do número de lags \\((k)\\):\n\\[\n\\mathbb{E}[y_{t}] = \\mu\n\\] \\[\n\\text{Var}[y_{t}] = \\mathbb{E}[(y_{t} - \\mu)^{2}] = \\sigma^2\n\\] \\[\n\\text{Cov}[y_{t},y_{t+k}] = \\mathbb{E} [ (y_{t} - \\mu)(y_{t-k} - \\mu)] = \\gamma_{k}\n\\]\n\n\n1.3.5 Função de autocorrelação (FAC)\nAo assumir a hipótese da estacionariedade, vamos ter que a função conjunta de probabilidade de \\(y_{t_{1}}\\) e \\(y_{t_{2}}\\) será a mesma para todo o tempo \\(t_{1}\\) e \\(t_{2}\\), que será constante. Isso implica que a covariância entre \\(y_{t}\\) e \\(y_{t+k}\\) será separada apenas por \\(k\\) intervalos de tempo (lag). Assim, a autocovariância ao lag \\(k\\) é definida por:\n\\[\n\\gamma_{k} = \\text{Cov}[y_{t},y_{t+k}] = \\mathbb{E} [ (y_{t} - \\mu)(y_{t-k} - \\mu)]\n\\]\nDa mesma forma, teremos que a autocorrelação é dada por:\n\\[\n\\rho_{k} = \\dfrac{\\mathbb{E} [ (y_{t} - \\mu)(y_{t-k} - \\mu)]}{\\sqrt{\\mathbb{E}[(y_{t} - \\mu)^{2}] \\mathbb{E}[(y_{t} - \\mu)^{2}] }} = \\dfrac{\\mathbb{E} [ (y_{t} - \\mu)(y_{t-k} - \\mu)]}{\\sigma^{2}}\n\\]\nComo em um processo estacionário a variância é constante, vamos ter que \\(\\gamma_{0} = \\sigma^{2}\\). Podemos então dizer que a autocorrelação no lag \\(k\\) é:\n\\[\n\\rho_{k} = \\dfrac{\\gamma_{k}}{\\gamma_{0}}\n\\]\nE isso implica que \\(\\rho_{0} = 1\\) se \\(k=0\\).\nA Função de autocorrelação é quando se plota um gráfico \\(\\rho_{k}\\) contra o lag \\(k\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introdução",
    "section": "",
    "text": "Note que se somarmos n vezes um parâmetro é o mesmo que dizer n vezes o parâmetro, logo \\(\\sum_{i=1}^{N}\\hat{\\alpha} = n\\hat{\\alpha}\\).↩︎\nVale lembrar que \\(B\\) sem chapéu é o melhor ajuste possível da reta, os valores que só Deus sabe.↩︎\nVale lembrar que \\((AB)' = B' A'\\)↩︎\nVariância dos erros é constante, isto é, \\(\\mathbb{E}(u_i^2) = \\sigma^2, \\, \\forall i=1, \\ldots, n\\)↩︎\nLembre-se da ideia de convergência de uma sequência. Dado um \\(\\varepsilon &gt; 0\\), dizemos que \\(x_{k} \\to x\\) se existir um \\(k_0\\), em que \\(\\forall k \\geq k_0 \\implies |x_{k} - x| &lt; \\varepsilon\\)↩︎\nChamada também de Distribuição normal gaussiana.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introdução</span>"
    ]
  },
  {
    "objectID": "cap-arima.html",
    "href": "cap-arima.html",
    "title": "2  ARIMA",
    "section": "",
    "text": "3 Modelos ARIMA\nAntes de chegar no modelo ARIMA, vou passar pelo AR, dps o MA.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ARIMA</span>"
    ]
  },
  {
    "objectID": "cap-arima.html#modelos-lineares-estacionários",
    "href": "cap-arima.html#modelos-lineares-estacionários",
    "title": "2  ARIMA",
    "section": "3.1 Modelos lineares estacionários",
    "text": "3.1 Modelos lineares estacionários\n\n3.1.1 Modelo Autorregressivo (AR)\nUm processo é dito autoregressivo quando ele carrega consigo msm uma certa persistência, quer dizer que o passado influencia o presente, quando apenas o período anterior influencia o atual vamos ter um AR(1) \\[\n\\begin{aligned}\n    y_{t}=\\phi y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\] onde \\(\\phi\\) é um coeficiente tbm chamado de peso, seria o peso da influencia de um período no outro. Um caso especial do processo autoregressivo é o AR(p) \\[\n\\begin{aligned}\n    y_{t}=\\phi_{1} y_{t-1} + \\phi_{2} y_{t-2} + ... + \\phi_{p} y_{t-p} + \\varepsilon_{t}\n\\end{aligned}\n\\] onde todos os pesos \\(\\phi\\) são diferentes de 0.\nPodemos reescrever esse AR(p) usando o operador lag \\[\n\\begin{aligned}\n    (1 - \\phi_{1}L - \\phi_{2}L^{2} - ... - \\phi_{p}L^{p} )y_{t}=\\varepsilon_{t}\n\\end{aligned}\n\\] ou então \\[\n\\begin{aligned}\n    \\phi(L) y_{t} = \\varepsilon_{t}\n\\end{aligned}\n\\] onde \\(\\phi(L) = 1 - \\phi_{1}L - \\phi_{2}L^{2} - ... - \\phi_{p}L^{p}\\).\nO processo autoregressivo deve respeitar algumas condições para ser estacionário. Seja o processo AR(1) para exemplificar \\[\n\\begin{aligned}\n    (1-\\phi L)y_{t} = \\varepsilon_{t}\n\\end{aligned}\n\\] e para que esse processo seja estacionário, devemos ter que todas as raízes de \\(|\\phi(L)| &gt; 1\\) e isso implica que o parâmetro \\(\\phi\\) do processo AR(1) deve ser $ &lt; 1$ para ser estacionário. Como a raiz de \\(1-\\phi L = 0\\) é \\(L=\\phi^{-1}\\), isso quer dizer que a raiz está fora do circulo unitário, já que \\(|\\phi| &lt; 1\\).\nO mesmo raciocínio pode ser levado para o processo autorregressivo de ordens superiores, seja o caso do AR(p) \\[\n\\begin{aligned}\n    \\phi(L)y_{t} = (1 - \\phi_{1}L - \\phi_{2}L^{2} - ... - \\phi_{p}L^{p} )y_{t}=\\varepsilon_{t}\n\\end{aligned}\n\\] onde a condição de estacionaridade é que TODAS AS RAÍZES de \\(\\phi(L)=0\\) devem ser menores que 1 em módulo, estar fora do círculo unitário. Existem alguns testes para ver se uma série é estacionária ou não, como o do Dickey-Fuller e KPSS, que serão abordados mais à frente.\nUm processo autorregressivo é dito inversível quando podemos reescrever o AR(1) em forma de MA\\((\\infty)\\), isso é usado em alguns casos como o das funções de impulso e resposta que são usadas quando queremos avaliar o quanto um choque em uma variável afeta a outra. Seja então o processo AR(1) \\[\n\\begin{aligned}\n    y_{t} = \\phi y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\] escrevendo na notação do operador lag \\[\n\\begin{aligned}\n    (1-\\phi L)y_{t} &= \\varepsilon_{t} \\\\\n    y_{t} &= \\dfrac{\\varepsilon_{t}}{(1-\\phi L)}\n\\end{aligned}\n\\] podemos ver que essa expressão tem a forma de um somatório de PG infinita e a única condição para que isso seja verdade é a de que \\(\\phi \\leq 1\\) para que ela seja convergente. Podemos então dizer que no caso da série ser estacionária podemos dizer que ela é inversível, sendo \\(\\varepsilon_{t}\\) o primeiro elemento e \\(\\phi L\\) a razão. Então é a mesma coisa que dizer que isso é \\[\n\\begin{aligned}\n    y_{t} = \\varepsilon_{t} + \\phi L \\varepsilon_{t} + \\phi^{2}L^{2} \\varepsilon_{t} + ...\n\\end{aligned}\n\\] ou ainda \\[\n\\begin{aligned}\n    y_{t} &= \\varepsilon_{t} + \\phi \\varepsilon_{t-1} + \\phi^{2} \\varepsilon_{t-2} + ... \\\\\n    y_{t} &= \\sum_{i=0}^{\\infty} \\phi^{i}\\varepsilon_{t-i}\n\\end{aligned}\n\\]\nAutocorrelação: De acordo com Box et al. (2015, 58), temos que o caso de um AR(1) satisfaz a seguinte condição \\[\n\\begin{aligned}\n    \\rho_{k}=\\phi_{1} \\rho_{k-1}\n\\end{aligned}\n\\] então para \\(k=1\\) \\[\n\\begin{aligned}\n     \\rho_{1} = \\phi_{1}\n\\end{aligned}\n\\] e resolvendo recursivamente \\[\n\\begin{aligned}\n    &\\rho_{2} = \\phi_{1} \\rho_{1} = \\phi_{1}^{2} \\\\\n    &\\rho_{3} = \\phi_{1} \\rho_{2} = \\phi_{1} \\phi_{1}^{2} = \\phi_{1}^{3} \\\\\n    \\therefore \\ &\\rho_{k}=\\phi_{1}^{k}\n\\end{aligned}\n\\]\nDa mesma maneira, podemos ver que a autocorrelação de um AR(2) satisfaz a seguinte condição \\[\n\\begin{aligned}\n    \\rho_{k}=\\phi_{1} \\rho_{k-1} + \\phi_{2} \\rho_{k-2}\n\\end{aligned}\n\\] então para \\(k=1\\) \\[\n\\begin{aligned}\n    \\rho_{1} = \\phi_{1} + \\phi_{2}\\rho_{-1}\n\\end{aligned}\n\\] como a correlação é simétrica, podemos trocar \\(\\rho_{-1} \\rightarrow \\rho_{1}\\) \\[\n\\begin{aligned}\n    \\rho_{1} &= \\phi_{1} + \\phi_{2}\\rho_{1} \\\\\n    \\rho_{1} &= \\dfrac{\\phi_{1}}{1-\\phi_{2}}\n\\end{aligned}\n\\] e resolvendo recursivamente \\[\n\\begin{aligned}\n    &\\rho_{2} = \\phi_{1} \\rho_{1} + \\phi_{2} \\rho_{0} \\\\\n    &\\rho_{2} = \\dfrac{\\phi_{1}^{2}}{1-\\phi_{2}} + \\phi_{2} \\\\\n    &\\rho_{3} = \\phi_{1} \\rho_{2} + \\phi_{2} \\rho_{1} \\\\\n    &\\rho_{3} = \\phi_{1} \\bigg[\\dfrac{\\phi_{1}^{2}}{1-\\phi_{2}} + \\phi_{2}\\bigg] + \\dfrac{\\phi_{1} \\phi_{2}}{1-\\phi_{2}} \\\\\n    & \\qquad \\vdots\n\\end{aligned}\n\\] *** terminar essa parte mais tarde**** \nVariância: Uma maneira fácil de se calcular a variância de um processo AR(1) é usando o operador da variância Var[.]: \\[\n\\begin{aligned}\n    \\text{Var}[y_{t}] &= \\text{Var}[\\phi y_{t-1}] + \\text{Var}[\\varepsilon_{t}] \\\\\n    \\text{Var}[y_{t}] &= \\phi^{2} \\text{Var}[y_{t}] + \\text{Var}[\\varepsilon_{t}] \\\\\n    \\text{Var}[y_{t}] &= \\phi^{2} \\text{Var}[y_{t}] + \\sigma_{\\varepsilon}^{2} \\\\\n    (1-\\phi^{2}) \\text{Var}[y_{t}] &= \\sigma_{\\varepsilon}^{2} \\\\\n    \\sigma_{y}^{2} &= \\dfrac{\\sigma_{\\varepsilon}^{2}}{(1-\\phi^{2})}\n\\end{aligned}\n\\] se vc observar o valor de \\(2+2\\) a variância é negativa, oq seria um absurdo; se \\(2+2\\) a variância vai para infinito e é por isso que quando o processo é não estacionário ele apresenta variância infinita.\nEXEMPLO: Seja a modelo \\(y_{t}=-0,3 y_{t-1} + 0,6 y_{t-2} + \\varepsilon_{t}\\), verifique se é estacionário.\nPodemos reescrever esse modelo usando o operador lag \\[\n\\begin{aligned}\n    (1+0,3L-0,6L^{2}) y_{t} = \\varepsilon_{t}\n\\end{aligned}\n\\] temos então aqui nesse exemplo que \\(\\phi(L) = 1+0,3L-0,6L^{2}\\) e como a condição para que o processo seja estacionário as raízes de \\(\\phi(L)=0\\) tem que ser maior que 1 em módulo. Vamos ter que \\[\n\\begin{aligned}\n    L &= \\dfrac{-0,3 \\pm \\sqrt{0,3^2 - 4(-0,6)}}{2(-0,6)} \\\\\n      &= \\dfrac{-0,3 \\pm 1,578}{-1,2} \\ \\Rightarrow \\ L=-1,065 \\ \\text{e} \\ 1,565\n\\end{aligned}\n\\] sendo todas as raízes maiores que um em modulo, então o processo é estacionário.\n\n\n3.1.2 Modelo de Média móvel (MA)\nO modelo de média móvel é uma extensão do processo de ruído branco, onde os parâmetros de peso são representados pelo símbolo \\(\\theta\\). O modelo é escrito da seguinte forma: \\[\n\\begin{aligned}\n    y_{t} = \\varepsilon_{t} + \\theta_{1}\\varepsilon_{t-1} + \\theta_{2}\\varepsilon_{t-2} + \\dots + \\theta_{q}\\varepsilon_{t-q}\n\\end{aligned}\n\\]\nO motivo pelo qual se usa esse tipo de modelo é que, em economia, estamos diante de diversos choques ao longo do tempo, seja por uma greve, desastres naturais, decisões do governo, etc. Esses choques normalmente não terão apenas um efeito imediato na série, muitas vezes apresentando um efeito contemporâneo, demorando a ser dissipado e tendo efeito ao longo do tempo em vários períodos consecutivos.\nSeja o modelo de MA(q) com \\(\\mu = 0\\) com esperança \\[\n\\begin{aligned}\n    \\mathbb{E}[y_{t}] &= \\mathbb{E}[\\varepsilon_{t} + \\theta_{1}\\varepsilon_{t-1} + \\theta_{2}\\varepsilon_{t-2} + \\dots + \\theta_{q}\\varepsilon_{t-q}] \\\\\n     &= 0\n\\end{aligned}\n\\] e variância \\[\n\\begin{aligned}\n    \\text{Var}[y_{t}] &= \\text{Var}[\\varepsilon_{t} + \\theta_{1}\\varepsilon_{t-1} + \\theta_{2}\\varepsilon_{t-2} + \\dots + \\theta_{q}\\varepsilon_{t-q}] \\\\\n    &= \\text{Var}[\\varepsilon_{t}] + \\text{Var}[\\theta_{1}\\varepsilon_{t-1}] + \\text{Var}[\\theta_{2}\\varepsilon_{t-2}] + \\dots + \\text{Var}[\\theta_{q}\\varepsilon_{t-q}] \\\\\n    &= \\sigma_{\\varepsilon}^{2} + \\theta_{1}^{2}\\sigma_{\\varepsilon}^{2} + \\theta_{2}^{2}\\sigma_{\\varepsilon}^{2} + \\dots + \\theta_{q}^{2}\\sigma_{\\varepsilon}^{2} \\\\\n    &= (1 + \\theta_{1}^{2} + \\theta_{2}^{2} + \\dots + \\theta_{q}^{2}) \\sigma_{\\varepsilon}^{2}\n\\end{aligned}\n\\] nota-se então que a variância de um modelo MA(2) é igual a \\(\\text{Var}[y_{t}] = (1 + \\theta_{1}^{2} + \\theta_{2}^{2}) \\sigma_{\\varepsilon}^{2}\\).\nInvertibilidade: As condições de invertibilidade do modelo são iguais às condições para que um modelo AR(p) seja estacionário, ou seja, \\(|\\theta| &lt; 1\\), ou que as raízes de \\(\\theta(L) = 0\\) sejam maiores que 1 em módulo.\nFunção de autocorrelação: Vamos ter a seguinte fórmula para o caso geral de um modelo MA(q), \\[\n\\begin{aligned}\n    \\rho_k= \\begin{cases}\\dfrac{-\\theta_k+\\theta_1 \\theta_{k+1}+\\dots+\\theta_{q-k} \\theta_q}{1+\\theta_1^2+\\dots+\\theta_q^2} & k=1,2, \\dots, q \\\\ 0 & k&gt;q\\end{cases}\n\\end{aligned}\n\\] onde temos que \\(\\gamma_{0} = (1+\\theta_1^2+\\dots+\\theta_q^2)\\sigma_{\\varepsilon}^{2}\\) e que \\(\\gamma_{k} = (-\\theta_k+\\theta_1 \\theta_{k+1}+\\dots+\\theta_{q-k} \\theta_q)\\sigma_{\\varepsilon}^{2}\\).\nUma coisa a se notar nessa equação é que, quando tivermos que o número de lags da função de autocorrelação for maior que a ordem do modelo, a FAC será igual a zero. Seja um modelo MA(2), então \\(\\rho_{3},\\dots,\\rho_{k} = 0\\).\nEssa equação pode ser aplicada para modelos MA(1) também: \\[\n\\begin{aligned}\n    \\rho_k= \\begin{cases}\n        \\dfrac{-\\theta_1}{1+\\theta_1^2} & k=1 \\\\\n        0 & k&gt;1\n    \\end{cases}\n\\end{aligned}\n\\] De forma análoga, para um MA(2) vamos ter: \\[\n\\begin{aligned}\n    & \\rho_1=\\dfrac{-\\theta_1 + \\theta_{1}\\theta_{2}}{1+\\theta_1^2+\\theta_2^2} \\\\\n    & \\rho_2=\\dfrac{-\\theta_2}{1+\\theta_1^2+\\theta_2^2}\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ARIMA</span>"
    ]
  },
  {
    "objectID": "cap-arima.html#modelos-lineares-não-estacionários",
    "href": "cap-arima.html#modelos-lineares-não-estacionários",
    "title": "2  ARIMA",
    "section": "3.2 Modelos lineares não-estacionários",
    "text": "3.2 Modelos lineares não-estacionários\nA maioria das séries temporais apresenta não estacionariedade, o que significa que em um modelo ARMA, se as raízes de \\(\\phi(L) = 0\\) estiverem fora do círculo unitário, a série é dita estacionária, mas quando estão fora do círculo unitário, ela terá um comportamento explosivo, sendo não estacionária. Um modelo ARMA sem sazonalidade pode ser escrito da seguinte forma: \\[\n\\begin{aligned}\n    \\phi(L) y_{t} = \\theta(L)\\varepsilon_{t}\n\\end{aligned}\n\\] Se \\(\\phi(L)\\) for um operador autorregressivo não estacionário, tal que \\(d\\) raízes de \\(\\phi(L)=0\\) são unitárias e o resto está fora do círculo unitário, esse modelo pode ser escrito como: \\[\n\\begin{aligned}\n    \\phi(L)(1-L)^{d} y_{t} = \\theta(L)\\varepsilon_{t}\n\\end{aligned}\n\\] onde \\(\\phi(L)\\) se torna um operador autorregressivo estacionário. Nesse caso, foi feita a separação de todas as raízes que estão fora do círculo unitário das raízes que estão dentro do círculo unitário. Sabendo que a diferenciação torna as raízes estacionárias, podemos usar o operador \\(\\nabla^{d} = (1-L)^{d}\\) para \\(d \\geq 1\\); aqui \\(\\nabla\\) é chamado de operador de diferenciação. \\[\n\\begin{aligned}\n    \\phi(L) \\nabla^{d} y_{t} = \\theta(L)\\varepsilon_{t}\n\\end{aligned}\n\\] Esse processo será conhecido como integração, o I do ARIMA\\((p,d,q)\\), onde a ordem de integração desse processo é dada pelo valor de \\(d\\). E se chamarmos \\(w_{t}= \\nabla^{d} y_{t}\\), o processo passa a ser escrito da seguinte forma: \\[\n\\begin{aligned}\n    \\phi(L) w_{t} = \\theta(L)\\varepsilon_{t}\n\\end{aligned}\n\\]\nAbaixo podemos ver alguns exemplos de processo ARIMA:\n\nO modelo ARIMA(0,1,1): \\[\n\\begin{aligned}\n     \\nabla y_{t} &= \\varepsilon_{t} - \\theta_{1}\\varepsilon_{t-1}\\\\\n                 &= (1-\\theta_{1}L)\\varepsilon_{t}\n\\end{aligned}\n\\] onde \\(p=0\\), \\(d=1\\), \\(q=1\\), \\(\\phi(L)=1\\), \\(\\theta(L)=(1-\\theta_{1}L)\\).\nO modelo ARIMA(1,1,1): \\[\n\\begin{aligned}\n     \\nabla y_{t} - \\phi_{1}\\nabla y_{t-1} &= \\varepsilon_{t} - \\theta_{1}\\varepsilon_{t-1}\\\\\n     (1 - \\phi_{1}L)\\nabla y_{t} &= (1-\\theta_{1}L)\\varepsilon_{t}\n\\end{aligned}\n\\] onde \\(p=1\\), \\(d=1\\), \\(q=1\\), \\(\\phi(L)=(1 - \\phi_{1}L)\\), \\(\\theta(L)=(1-\\theta_{1}L)\\).\n\nEXAMPLE: Seja a modelo \\(y_{t}=0,1 y_{t-1} + 0,9 y_{t-2} + \\varepsilon_{t}\\), verifique se é estacionário.\nReescrevendo usando o operador lag: \\[\n\\begin{aligned}\n(1-0,1L-0,9L^{2})y_{t}&=\\varepsilon_{t} \\\\\n(0,9)(1,1111-0,1111L-L^{2})y_{t}&=\\varepsilon_{t}\n\\end{aligned}\n\\] Usando a fórmula quadrática, vamos encontrar que as raízes de \\(\\phi(L)\\) são -1,1111 e 1; como uma das raízes é igual a 1, esse processo é não estacionário. Reescrevendo, temos: \\[\n\\begin{aligned}\n(0,9)(L+1,1111)(L-1)y_{t}&=\\varepsilon_{t} \\\\\n(1+0,9L)(L-1)y_{t}&=\\varepsilon_{t} \\\\\n(1+0,9L)(1-L)y_{t}&=\\varepsilon_{t} \\\\\n(1+0,9L)\\nabla y_{t}&=\\varepsilon_{t}\n\\end{aligned}\n\\] Assim sendo um modelo ARIMA(1,1,1) pois temos \\(\\nabla y_{t}\\) que corresponde à integração de ordem 1 (I(1)). Também pode ser reescrito da seguinte maneira: \\[\n\\begin{aligned}\n(1+0,9L)w_{t}&=\\varepsilon_{t}\n\\end{aligned}\n\\] Mas note, que como aqui não temos o operador de diferenciação, este modelo é um ARMA(1,1).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ARIMA</span>"
    ]
  },
  {
    "objectID": "cap-arima.html#testes-de-raiz-unitária---dick-fuller",
    "href": "cap-arima.html#testes-de-raiz-unitária---dick-fuller",
    "title": "2  ARIMA",
    "section": "5.1 Testes de Raiz Unitária - Dick-Fuller",
    "text": "5.1 Testes de Raiz Unitária - Dick-Fuller\nO teste de Dick-Fuller é o teste mais usado para detectar a presença de raiz unitária, na qual a hipótese nula é se a série é um passeio aleatório, contra a hipótese alternativa se a série é estacionária. Para mostrar o teste, vamos usar um AR(1), \\[\n\\begin{aligned}\ny_{t} &= \\phi y_{t-1} + \\varepsilon_{t}, \\quad \\text{onde} \\quad \\varepsilon_{t} \\sim \\text{i.i.d. } \\mathcal{N}(0,\\: \\sigma^2)\n\\end{aligned}\n\\] onde já sabemos que se \\(\\phi = 1\\) o processo é um passeio aleatório e se \\(\\phi &lt; 1\\) ele é um processo estacionário. Aqui vamos ter que esse \\(\\phi\\) é um parâmetro estimado por MQO, por isso precisamos aplicar um teste a esse parâmetro para saber o quão confiável é esse coeficiente que foi estimado, para isso, Dick-Fuller aplicaram um teste de regressão que é derivado desse modelo AR(1), subtraindo \\(y_{t-1}\\) de ambos os lados: \\[\n\\begin{aligned}\ny_{t} - y_{t-1} &= \\phi y_{t-1} - y_{t-1} + \\varepsilon_{t} \\\\\n\\nabla y_{t} &= (\\phi - 1)y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\] Substituindo \\(\\delta = \\phi - 1\\), temos: \\[\n\\begin{aligned}\n\\nabla y_{t} &= \\delta y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\] Usando essa equação, pode-se investigar que se \\(\\phi=1 \\Rightarrow \\delta =0\\) e isso implica que \\(\\nabla y_{t} = \\varepsilon_{t}\\) sendo um passeio aleatório; caso contrário, se \\(\\phi &lt; 1 \\Rightarrow \\delta \\neq 0\\) sendo um processo estacionário. Então a ideia desse teste de DF é olhar para o \\(\\delta\\), onde: \\[\n\\begin{aligned}\nH_0 \\: : \\: \\delta = 0\n\\end{aligned}\n\\] Se a hipótese nula não for rejeitada (satisfeita ou aceita), vamos ter que \\(y_{t}\\) é integrado de ordem 1, tal que \\(y_{t} \\: \\sim \\: I(1)\\), pois será estacionário após uma defasagem. A hipótese alternativa tem a seguinte forma: \\[\n\\begin{aligned}\nH_a \\: : \\: \\delta \\neq 0\n\\end{aligned}\n\\] Então se a hipótese nula for rejeitada, implica que \\(y_{t} \\: \\sim \\: I(1)\\), sendo a série estacionária. O interessante aqui é que com essa regressão de teste, conseguimos aplicar uma estatística de teste \\((\\tau)\\) em \\(\\delta\\), podendo assim comparar essa estatística do modelo com valores já calculados por Dick-Fuller, chamados de \\(\\tau_{c}\\) (tau calculado), assim: - Se \\(\\tau &lt; \\tau_{c}\\) \\(\\Rightarrow\\) rejeita \\(H_0\\) (não estacionário) - Se \\(\\tau &gt; \\tau_{c}\\) \\(\\Rightarrow\\) NÃO rejeita \\(H_0\\) (estacionário)\nEsse valor de teste é um simples teste \\(t\\), onde: \\[\n\\begin{aligned}\n\\hat{t}_{DF} &= \\dfrac{\\hat{\\delta}}{SE(\\hat{\\delta})} = \\dfrac{\\phi-1}{SE(\\phi)}\n\\end{aligned}\n\\] SE corresponde ao standard error (erro padrão).\nEsse teste de DF pode ser modificado para caso a série tenha um drift, adicionando uma constante e um termo de tendência, assumindo a seguinte forma \\[\n\\begin{aligned}\n\\nabla y_{t} &= \\beta_{1} + \\beta_{2}t + \\delta y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\]\na hipótese nula permanece a mesma. Para saber se essa constante e o termo de tendência são significantes, temos que olhar a estatística de teste \\(t\\) de cada beta, ou olhar para seus .\nEsse teste de Dick-Fuller é simples e não permite testar a persistência do processo, pois os resíduos podem ser autocorrelacionados. Assim, foi desenvolvido o teste de Dick-Fuller Aumentado (ADF) para controlar essa autocorrelação nos resíduos, possibilitando testar valores de lag maiores (AR(.) de ordem superior). Vamos considerar a regressão de teste para um AR(1) \\[\n\\begin{aligned}\n\\nabla y_{t} &= \\beta_{1} + \\beta_{2}t + \\delta y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\]\nse acharmos que \\(\\nabla y_{t}\\) segue um AR(2), a regressão de teste será \\[\n\\begin{aligned}\n\\nabla y_{t} &= \\beta_{1} + \\beta_{2}t + \\delta y_{t-1} + \\gamma \\nabla y_{t-1} + \\varepsilon_{t}\n\\end{aligned}\n\\]\ngeneralizando isso para um processo AR(p), temos \\[\n\\begin{aligned}\n\\nabla y_{t} &= \\beta_{1} + \\beta_{2}t + \\delta y_{t-1} + \\sum_{i=0}^{m} \\gamma_{i} \\nabla y_{t-i} + \\varepsilon_{t}\n\\end{aligned}\n\\]\nAqui, a hipótese é a mesma, sendo \\(H_0: \\delta = 0\\) não estacionário e \\(H_a: \\delta &lt; 0\\) estacionário. A significância dos \\(\\gamma\\) pode ser testada através de um teste \\(t\\).\n\n5.1.1 Teste de autocorrelação - Ljung–Box e Box-Pierce\nO teste de Ljung–Box pode ser definido como\n\n\\(H_0:\\) os erros são independentemente distribuídos\n\\(H_A:\\) os erros NÃO são independentemente distribuídos; existe correlação serial\n\nNão há muito mais o que comentar nesse teste, apenas mostrar que a estatística de teste do Ljung–Box é \\[\n\\begin{aligned}\nLB(k) = N(N+2)\\sum_{j=1}^{k}(N-j)^{-1} \\hat{\\rho}_{j}^{2}(\\hat{\\varepsilon})\n\\end{aligned}\n\\]\ne que o teste Q (Box-Pierce) é \\[\n\\begin{aligned}\nQ(k) = N \\sum_{j=1}^{k}\\hat{\\rho}_{j}^{2}(\\hat{\\varepsilon})\n\\end{aligned}\n\\]\nonde \\(\\rho_{j}\\) é a correlação dos resíduos ao lag \\(j\\) e \\(N\\) é o tamanho da amostra. Como aqui as estatísticas de teste se distribuem como uma qui-quadrado com \\(k-p-q\\). Rejeita-se \\(H_0\\) se \\[\n\\begin{aligned}\nQ,LB &gt; \\tau\n\\end{aligned}\n\\]\nsendo \\(\\tau = \\chi_{\\alpha}^{2}(k-p-q)\\), em que \\(\\alpha\\) é o nível de significância.\n\n\n5.1.2 Teste de heterocedasticidade - ARCH-LM\nO teste ARCH lagrange multiplier ou ARCH-LM é usado para detectar heterocedasticidade e é bem simples. Ele testa se os erros da regressão são variantes no tempo sem de fato estimar um parâmetro . A estimação desse teste pode seguir a seguinte metodologia em dois passos:\n\nEstimar via MQO a equação da regressão mais adequada ou usar um modelo ARMA e assumir que \\(\\hat{\\varepsilon}_{t}^{2}\\) seja o erro quadrático ajustado.\nRegressar os erros quadráticos contra uma constante e com \\(q\\) lags desses valores \\(\\hat{\\varepsilon}_{t-1}^{2},\\hat{\\varepsilon}_{t-2}^{2},...,\\hat{\\varepsilon}_{t-q}^{2}\\), estimando a seguinte regressão\n\n\\[\n\\begin{aligned}\n\\hat{\\varepsilon}_{t}^{2} = \\alpha_{0} + \\alpha_{1}\\hat{\\varepsilon}_{t-1}^{2} + \\alpha_{2}\\hat{\\varepsilon}_{t-2}^{2} + ... + \\alpha_{q}\\hat{\\varepsilon}_{t-q}^{2}\n\\end{aligned}\n\\]\nSe não houver efeito ARCH ou GARCH, os valores estimados de \\(\\alpha_{1}\\) até \\(\\alpha_{q}\\) têm que ser zero. Essa regressão apresentará pouco poder explicatório, o que significa que o \\(R^{2}\\) será pequeno. Usando um tamanho de amostra \\(T\\), a estatística de teste \\(TR^{2}\\) (vale ressaltar que isso é um produto) converge para uma distribuição \\(\\chi^{2}\\) com \\(q\\) graus de liberdade. Por isso, esse tipo de teste entra na categoria de testes assintóticos, que dependem do tamanho da amostra. Se a amostra for muito pequena, o valor do teste \\(TR^{2}\\) será superestimado, mas para amostras grandes, ele funciona bem. A hipótese nula aqui é \\(H_0:\\varepsilon_{t}\\) sem efeito ARCH (sem heterocedasticidade); \\(H_a:\\varepsilon_{t}\\) tem efeito ARCH (tem heterocedasticidade). A hipótese nula é rejeitada se \\(TR^{2} &gt; \\tau\\).\n\n\n5.1.3 Teste de normalidade - Jarque-Bera\nDificilmente dados empíricos passam no teste de normalidade dos dados. O mais famoso teste para testar se os dados estão normalmente distribuídos é o teste de Jarque-Bera. CONTINUAR\n\n\n\n\nBox, George EP, Gwilym M Jenkins, Gregory C Reinsel, e Greta M Ljung. 2015. Time series analysis: forecasting and control. John Wiley & Sons.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ARIMA</span>"
    ]
  },
  {
    "objectID": "cap-vol.html",
    "href": "cap-vol.html",
    "title": "3  Modelos de volatilidade",
    "section": "",
    "text": "3.1 Modelos lineares",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de volatilidade</span>"
    ]
  },
  {
    "objectID": "cap-vol.html#modelos-lineares",
    "href": "cap-vol.html#modelos-lineares",
    "title": "3  Modelos de volatilidade",
    "section": "",
    "text": "3.1.1 ARCH\nSeja o modelo \\[\n\\begin{aligned}\ny_{t} = \\mathbb{E}[y_{t} \\! \\mid I_{t-1}] + \\nu_{t}\n\\end{aligned}\n\\]\nonde \\(\\nu_{t} \\sim i.i.d \\, (0, \\, h_{t})\\) representa o erro do modelo, com média zero e uma variância \\(h_{t}\\) que é condicional ao conjunto de informações passadas \\(I_{t-1} = \\{y_{1}, x_{1}, ..., y_{t-1}, x_{t-1}\\}\\) e \\(\\nu_{t}\\) pode ser separado em duas partes, uma é a parte estocástica \\(\\varepsilon_{t} \\sim i.i.d \\, (0, \\, 1)\\) e a outra é o desvio padrão condicional que depende do tempo \\(h^{\\frac{1}{2}}\\). Logo, a variância de \\(\\nu_{t}\\) é \\[\n\\begin{aligned}\n\\mathbb{E}[\\nu_{t}^{2} \\mid I_{t-1} ] = h_{t}\n\\end{aligned}\n\\]\nAssumindo que a média é zero, podemos escrever o modelo ARCH básico da seguinte forma \\[\n\\begin{aligned}\ny_{t}=h_{t}^{\\frac{1}{2}} \\varepsilon_{t}\n\\end{aligned}\n\\]\ncomo \\(h\\) é a variância condicional ao conjunto de informação, ele é definido como \\[\n\\begin{aligned}\nh_{t}=w + \\alpha y_{t-1}^{2}\n\\end{aligned}\n\\]\nonde ele depende de uma constante e do quadrado da informação passada.\nNote que, como está ao quadrado a informação passada, o modelo ARCH, que é da classe dos lineares, atribui peso igual para volatilidade tanto negativa quanto positiva. A ideia central desse tipo de modelo é conseguir separar a volatilidade condicional do ruído branco e modelar essa volatilidade condicional \\(h_{t}\\).\nModelo AR-ARCH: Como aqui nos modelos de volatilidade nós estamos considerando o \\(y_{t}\\) como uma série de retornos, pode acontecer de que os retornos sejam correlacionados, ainda que fracamente, sendo então adicionado um AR(1) ao modelo \\[\n\\begin{aligned}\ny_{t} &= \\phi y_{t-1} + h_{t}^{\\frac{1}{2}} \\varepsilon_{t} \\\\\nh_{t} &=w + \\alpha y_{t-1}^{2}\n\\end{aligned}\n\\]\nem que \\(\\phi\\) mede a correlação entre os retornos no tempo \\(t\\) e \\(t-1\\).\n\n\n3.1.2 GARCH\nEsse modelo é uma extensão do modelo ARCH. Aqui, ele inclui dentro da variância sua própria defasagem. Podemos escrever o modelo GARCH(1,1) da seguinte maneira \\[\n\\begin{aligned}\ny_{t} &= \\phi y_{t-1} + h_{t}^{\\frac{1}{2}} \\varepsilon_{t} \\\\\nh_{t} &= w + \\alpha y_{t-1}^{2} + \\beta h_{t-1}\n\\end{aligned}\n\\]\ne um modelo GARCH(p,q) é dado por \\[\n\\begin{aligned}\nh_{t} = w + \\sum_{i=1}^{q} \\alpha_{i}y_{t-i}^{2} + \\sum_{i=1}^{p} \\beta h_{t-p}\n\\end{aligned}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de volatilidade</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Box, George EP, Gwilym M Jenkins, Gregory C Reinsel, and Greta M Ljung.\n2015. Time Series Analysis: Forecasting and Control. John Wiley\n& Sons.\n\n\nEnders, W. 2014. Applied Econometric Times Series. Wiley Series\nin Probability and Statistics. Wiley. https://books.google.com.br/books?id=lmr9oQEACAAJ.\n\n\nHamilton, James Douglas. 1994. Time Series Analysis. Princeton\nuniversity press.\n\n\nKotze, Kevin. 2019. “Time Series Analusis.” 2019. https://www.economodel.com/time-series-analysis-2019.",
    "crumbs": [
      "Referencias"
    ]
  }
]